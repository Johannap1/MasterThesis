{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4ad2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General \n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from matplotlib import cm\n",
    "#GPyTorch\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import gpytorch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.variational import CholeskyVariationalDistribution\n",
    "from gpytorch.variational import VariationalStrategy\n",
    "import tqdm\n",
    "#Sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#TSP\n",
    "from python_tsp.exact import solve_tsp_dynamic_programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ca4e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindCalculator:\n",
    "    def __init__(self,windfield_params):\n",
    "        self.windfield_params = windfield_params\n",
    "        self.windfield_params = windfield_params\n",
    "        self.use_custom_windfield = self.windfield_params['use_custom_windfield']\n",
    "        self.wind_direction = self.windfield_params['wind_direction']\n",
    "        self.wind_velocity = self.windfield_params['wind_velocity']\n",
    "        wind_norm = np.sqrt(self.wind_direction[0] ** 2 + self.wind_direction[1] ** 2 + self.wind_direction[2] ** 2)\n",
    "        self.wind_direction = self.wind_direction / wind_norm\n",
    "        if self.use_custom_windfield:\n",
    "            windfield_path= self.windfield_params['windfield_path']\n",
    "            try:\n",
    "                f = open(windfield_path)\n",
    "            except:\n",
    "                print(\"File '\" + windfield_path + \"' does not exist!\")\n",
    "                exit(1)\n",
    "\n",
    "            name = \"\"\n",
    "            data = dict()\n",
    "            for i in range(26):\n",
    "                val = f.readline()\n",
    "                if i % 2 == 0:\n",
    "                    val = str(val)\n",
    "                    val = val.replace(\" \", \"\")\n",
    "                    val = val.replace(\"\\n\", \"\")\n",
    "                    val = val.replace(\":\", \"\")\n",
    "                    name = val\n",
    "                else:\n",
    "                    line = np.fromstring(str(val), sep=\" \")\n",
    "                    if (len(line) == 1):\n",
    "                        line = line[0]\n",
    "                    data[name] = line\n",
    "\n",
    "            self.min_x_ = data[\"min_x\"]\n",
    "            self.min_y_ = data[\"min_y\"]\n",
    "            self.n_x_ = int(data[\"n_x\"])\n",
    "            self.n_y_ = int(data[\"n_y\"])\n",
    "            self.res_x_ = data[\"res_x\"]\n",
    "            self.res_y_ = data[\"res_y\"]\n",
    "            self.vertical_spacing_factors_ = data[\"vertical_spacing_factors\"]\n",
    "            self.bottom_z_ = data[\"bottom_z\"]\n",
    "            self.top_z_ = data[\"top_z\"]\n",
    "            self.u_vec_ = data[\"u\"]\n",
    "            self.v_vec_ = data[\"v\"]\n",
    "            self.w_vec_ = data[\"w\"]\n",
    "\n",
    "            self.n_z = len(self.vertical_spacing_factors_)\n",
    "\n",
    "    def linear_interpolation(self, position, values, points):\n",
    "        value = values[0] + (values[1] - values[0]) / (points[1] - points[0]) * (position - points[0])\n",
    "        return value\n",
    "\n",
    "    def bilinear_interpolation(self, position, values, points):\n",
    "        intermediate_values = np.array([self.linear_interpolation(position[0], values[0:], points[0:]),\n",
    "                                        self.linear_interpolation(position[0], values[2:], points[2:])])\n",
    "        value = self.linear_interpolation(position[1], intermediate_values, points[4:])\n",
    "        return value\n",
    "\n",
    "    def trilinear_interpolation(self, position, values, points):\n",
    "        intermediate_values = np.array([self.linear_interpolation(position[2], values[0:], points[0:]),\n",
    "                                        self.linear_interpolation(position[2], values[2:], points[2:]),\n",
    "                                        self.linear_interpolation(position[2], values[4:], points[4:]),\n",
    "                                        self.linear_interpolation(position[2], values[6:], points[6:])])\n",
    "        value = self.bilinear_interpolation(position[0:],intermediate_values, points[8:])\n",
    "        return value\n",
    "\n",
    "    def calculate_windfield(self, link_position):\n",
    "\n",
    "        if self.use_custom_windfield:\n",
    "            # Calculate x,y index just smaller than aircraft position or equal to\n",
    "            x_inf = math.floor((link_position[0] - self.min_x_) / self.res_x_)\n",
    "            y_inf = math.floor((link_position[1] - self.min_y_) / self.res_y_)\n",
    "\n",
    "            # In case aircraft is on one of the boundary surfaces at max_x or max_y,\n",
    "            # decrease x_inf, y_inf by one to have x_sup, y_sup on max_x, max_y.\n",
    "            if x_inf == self.n_x_ - 1:\n",
    "                x_inf = self.n_x_ - 2\n",
    "            if y_inf == self.n_y_ - 1:\n",
    "                y_inf = self.n_y_ - 2\n",
    "\n",
    "            # Calculate x,y index just larger than aircraft position\n",
    "            x_sup = x_inf + 1\n",
    "            y_sup = y_inf + 1\n",
    "\n",
    "            # Save grid points enclosing the aircraft in an array\n",
    "            n_vertices = 8\n",
    "            idx_x = np.array([x_inf, x_inf, x_sup, x_sup, x_inf, x_inf, x_sup, x_sup])\n",
    "            idx_y = np.array([y_inf, y_inf, y_inf, y_inf, y_sup, y_sup, y_sup, y_sup])\n",
    "\n",
    "            # Find vertical factors in each of the four surrounding\n",
    "            # grid columns, and their minimal/maximal value.\n",
    "            n_columns = 4\n",
    "            vertical_factors_columns = np.empty(n_columns)\n",
    "            for i in range(n_columns):\n",
    "                vertical_factors_columns[i] = (link_position[2] - self.bottom_z_[\n",
    "                    idx_x[2 * i] + idx_y[2 * i] * self.n_x_]) \\\n",
    "                                              / (self.top_z_[idx_x[2 * i] + idx_y[2 * i] * self.n_x_] -\n",
    "                                                 self.bottom_z_[idx_x[2 * i] + idx_y[2 * i] * self.n_x_])\n",
    "\n",
    "            # Find minimal and maximal vertical factor\n",
    "            vertical_factors_min = min(min(min(\n",
    "                vertical_factors_columns[0], vertical_factors_columns[1]),\n",
    "                vertical_factors_columns[2]), vertical_factors_columns[3])\n",
    "            vertical_factors_max = max(max(max(\n",
    "                vertical_factors_columns[0], vertical_factors_columns[1]),\n",
    "                vertical_factors_columns[2]), vertical_factors_columns[3])\n",
    "\n",
    "            # Check if aircraft is out of wind field or not, and act accordingly.\n",
    "            if (x_inf >= 0 and y_inf >= 0 and vertical_factors_max >= 0 and\n",
    "                    x_sup <= (self.n_x_ - 1) and y_sup <= (self.n_y_ - 1) and vertical_factors_min <= 1):\n",
    "                # Find indices in z-direction for each of the vertices.If link is not\n",
    "                # within the range of one of the columns, set to lowest or highest two.\n",
    "                idx_z = [0, int(len(self.vertical_spacing_factors_)) - 1,\n",
    "                         0, int(len(self.vertical_spacing_factors_)) - 1,\n",
    "                         0, int(len(self.vertical_spacing_factors_)) - 1,\n",
    "                         0, int(len(self.vertical_spacing_factors_)) - 1]\n",
    "                for i in range(n_columns):\n",
    "                    if vertical_factors_columns[i] < 0:\n",
    "                        # Link z - position below lowest grid point of that column\n",
    "                        idx_z[2 * i + 1] = 1\n",
    "                    elif vertical_factors_columns[i] >= 1:\n",
    "                        # Link z-position above highest grid point of that column\n",
    "                        idx_z[2 * i] = len(self.vertical_spacing_factors_) - 2\n",
    "                    else:\n",
    "                        # Link z-position between two grid points in that column.\n",
    "                        for j in range(len(vertical_factors_columns) - 1):\n",
    "                            if self.vertical_spacing_factors_[j] <= vertical_factors_columns[i] < \\\n",
    "                                    self.vertical_spacing_factors_[j + 1]:\n",
    "                                idx_z[2 * i] = j\n",
    "                                idx_z[2 * i + 1] = j + 1\n",
    "                                break\n",
    "\n",
    "                # Extract the wind velocities corresponding to each vertex\n",
    "                wind_at_vertices = np.empty([8, 3])\n",
    "                for i in range(n_vertices):\n",
    "                    wind_at_vertices[i, 0] = self.u_vec_[\n",
    "                        idx_x[i] + idx_y[i] * self.n_x_ + idx_z[i] * self.n_x_ * self.n_y_]\n",
    "                    wind_at_vertices[i, 1] = self.v_vec_[\n",
    "                        idx_x[i] + idx_y[i] * self.n_x_ + idx_z[i] * self.n_x_ * self.n_y_]\n",
    "                    wind_at_vertices[i, 2] = self.w_vec_[\n",
    "                        idx_x[i] + idx_y[i] * self.n_x_ + idx_z[i] * self.n_x_ * self.n_y_]\n",
    "\n",
    "                # Extract the relevant coordinate of every point needed for trilinear interpolation\n",
    "                n_points_interp_z = 8\n",
    "                n_points_interp_x = 4\n",
    "                n_points_interp_y = 2\n",
    "                interpolation_points = np.empty(n_points_interp_x + n_points_interp_y + n_points_interp_z)\n",
    "                for i in range(n_points_interp_x + n_points_interp_y + n_points_interp_z):\n",
    "                    if i < n_points_interp_z:\n",
    "                        interpolation_points[i] = (self.top_z_[idx_x[i] + idx_y[i] * self.n_x_] - self.bottom_z_[\n",
    "                            idx_x[i] + idx_y[i] * self.n_x_]) \\\n",
    "                                                  * self.vertical_spacing_factors_[idx_z[i]] + self.bottom_z_[\n",
    "                                                      idx_x[i] + idx_y[i] * self.n_x_]\n",
    "                    elif n_points_interp_z <= i < n_points_interp_x + n_points_interp_z:\n",
    "                        interpolation_points[i] = self.min_x_ + self.res_x_ * idx_x[2 * (i - n_points_interp_z)]\n",
    "                    else:\n",
    "                        interpolation_points[i] = self.min_y_ + self.res_y_ * idx_y[\n",
    "                            4 * (i - n_points_interp_z - n_points_interp_x)]\n",
    "\n",
    "                wind_v = self.trilinear_interpolation(link_position, wind_at_vertices, interpolation_points)\n",
    "            else:\n",
    "                print(\"Drone is outside of specified custom windfield, using default one\")\n",
    "                wind_v = self.wind_direction * self.wind_velocity\n",
    "        else:\n",
    "            wind_v = self.wind_direction * self.wind_velocity\n",
    "        return wind_v\n",
    "\n",
    "    def return_ground_truth(self):\n",
    "        mean = []\n",
    "        x = self.windfield_params['x'].flatten()\n",
    "        y = self.windfield_params['y'].flatten()\n",
    "        for i in range(x.size):\n",
    "            link_position = [x[i], y[i], 2] #Random z parameter for now\n",
    "            wind_v = self.calculate_windfield(link_position)\n",
    "            mean.append(wind_v)\n",
    "        mean = np.array(mean)\n",
    "        return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abac588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid(start, stop, res, array_type = None):\n",
    "    x = np.linspace(start, stop, res)\n",
    "    y = np.linspace(start, stop, res)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    if array_type is None:\n",
    "        X = np.stack((x.flatten(), y.flatten()), axis=-1)\n",
    "    else:\n",
    "        X = torch.FloatTensor(np.stack((x.flatten(), y.flatten()), axis=-1))\n",
    "    return X, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d873d9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPModel(ApproximateGP):\n",
    "    def __init__(self, inducing_points):\n",
    "        variational_distribution = CholeskyVariationalDistribution(inducing_points.size(0))\n",
    "        variational_strategy = VariationalStrategy(self, inducing_points, variational_distribution, learn_inducing_locations=True)\n",
    "        super(GPModel, self).__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ZeroMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=2))\n",
    "        #self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel(nu=0.5, ard_num_dims=2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca968dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseGPyTorchRegression:\n",
    "    def __init__(self, data, batch_size, epochs):\n",
    "        # Change dataset to torch tensor\n",
    "        self.data = data\n",
    "        data.read_data(\"torch\")\n",
    "        self.likelihood = []\n",
    "        self.model = []\n",
    "        self.batch_size = batch_size\n",
    "        self.n_epochs = epochs\n",
    "        self.sigma_f = []\n",
    "        self.length_scale = []\n",
    "        self.sigma_n = []\n",
    "    def fit(self):\n",
    "        for i in range(self.data.y.shape[1]):\n",
    "            train_dataset = TensorDataset(self.data.X_train, self.data.y_train[:,i])\n",
    "            train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "            inducing_points = self.data.X_train[::int(self.data.y.shape[0]/30), :]\n",
    "            model = GPModel(inducing_points=inducing_points)\n",
    "            likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "            model.train()\n",
    "            likelihood.train()\n",
    "            # Use the adam optimizer\n",
    "            optimizer = torch.optim.Adam([\n",
    "                {'params': model.parameters()},\n",
    "                {'params': likelihood.parameters()},\n",
    "            ], lr=0.01)\n",
    "            # \"Loss\" for GPs - the marginal log likelihood\n",
    "            mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=self.data.y_train[:,i].size(0))\n",
    "            num_epochs = self.n_epochs\n",
    "            epochs_iter = tqdm.notebook.tqdm(range(num_epochs), desc=\"Epoch\")\n",
    "            for i in epochs_iter:\n",
    "                # Within each iteration, we will go over each minibatch of data\n",
    "                minibatch_iter = tqdm.notebook.tqdm(train_loader, desc=\"Minibatch\", leave=False)\n",
    "                for x_batch, y_batch in minibatch_iter:\n",
    "                    optimizer.zero_grad()\n",
    "                    output = likelihood(model(x_batch))\n",
    "                    loss = -mll(output, y_batch)\n",
    "                    minibatch_iter.set_postfix(loss=loss.item())\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            self.likelihood.append(likelihood)\n",
    "            self.model.append(model)\n",
    "        #self.save_kernel_params()\n",
    "        \n",
    "    def get_kernel_params(self):\n",
    "        for i in range(self.data.y.shape[1]):\n",
    "            outputscale_constraint = self.model[i].covar_module.raw_outputscale_constraint\n",
    "            self.sigma_f.append(outputscale_constraint.transform(self.model[i].covar_module.raw_outputscale).detach().numpy())\n",
    "            self.length_scale.append([outputscale_constraint.transform(self.model[i].covar_module.base_kernel.raw_lengthscale).detach().numpy().item(0),\n",
    "                                      outputscale_constraint.transform(self.model[i].covar_module.base_kernel.raw_lengthscale).detach().numpy().item(1)])\n",
    "            noise_constraint = self.likelihood[i].noise_covar.raw_noise_constraint\n",
    "            self.sigma_n.append(noise_constraint.transform(self.likelihood[i].noise_covar.raw_noise).detach().numpy())\n",
    "    def save_kernel_params(self):\n",
    "        self.get_kernel_params()\n",
    "        for i in range(self.data.y.shape[1]):\n",
    "            name = \"gpytorch_y\" + str(i+1) + \"_\" + str(self.batch_size) + \"_\" + str(self.n_epochs)\n",
    "            self.data.save_kernel_params(name, self.length_scale[i], self.sigma_f[i], self.variance[i], self.sigma_n[i])\n",
    "    def predict(self, X_test=None):\n",
    "        if X_test == None:\n",
    "            X_test = self.X_test\n",
    "        self.mean = np.empty(X_test.shape)\n",
    "        self.upper = np.empty(X_test.shape)\n",
    "        self.lower = np.empty(X_test.shape)\n",
    "        for i in range(self.data.y.shape[1]):\n",
    "            self.model[i].eval()\n",
    "            self.likelihood[i].eval()\n",
    "            observed_pred = self.likelihood[i]((self.model[i](X_test)))\n",
    "            self.mean[:,i] = observed_pred.mean.detach().numpy()\n",
    "            lower, upper = observed_pred.confidence_region()\n",
    "            self.upper[:,i] = upper.detach().numpy()\n",
    "            self.lower[:,i] = lower.detach().numpy()\n",
    "    def get_covar(self, X_test):\n",
    "        for i in range(self.data.y.shape[1]):\n",
    "            self.model[i].eval()\n",
    "            self.likelihood[i].eval()\n",
    "            observed_pred =  self.likelihood[i]((self.model[i](X_test)))\n",
    "            covar = observed_pred.covariance_matrix.detach().numpy()\n",
    "            print(covar)\n",
    "        #name = \"gpytorch\" + \"_\" + str(self.batch_size) + \"_\" + str(self.n_epochs)\n",
    "        #self.data.save_prediction(name, self.mean, self.upper, self.lower)\n",
    "    def save_model(self, type):\n",
    "        for i in range(self.data.y.shape[1]):\n",
    "            #print(self.model[i].state_dict())\n",
    "            name = \"gpytorch_y\" + str(i+1) + type + \"_model.pth\"\n",
    "            torch.save(self.model[i].state_dict(), name)\n",
    "            print(self.likelihood[i].state_dict())\n",
    "            name = \"gpytorch_y\" + str(i+1) + type + \"_likelihood.pth\"\n",
    "            torch.save(self.likelihood[i].state_dict(), name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7c90a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wind_field(X=None, y=None, res=8, title=None, name=None):\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    plt.axis('equal')\n",
    "    plt.grid(linestyle=':')\n",
    "    q = plt.quiver(X[::res, 0], X[::res, 1], y[::res,0], y[::res,1], scale=2.54, color='r',\n",
    "                   units='width', scale_units=\"inches\", width=0.003)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel('x [m]', fontsize=14)\n",
    "    plt.ylabel('y [m]', fontsize=14)\n",
    "    plt.rc('xtick', labelsize=14) \n",
    "    plt.rc('ytick', labelsize=14) \n",
    "    plt.ioff()\n",
    "    plt.autoscale()\n",
    "    if not name==None:\n",
    "        plt.savefig(name,  bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f87aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_path(X=None,  res=8, title=None, name=None):\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    plt.axis('equal')\n",
    "    plt.grid(linestyle=':')\n",
    "    plt.plot(X[::res, 0], X[::res, 1], 'k--')\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel('x [m]', fontsize=14)\n",
    "    plt.ylabel('y [m]', fontsize=14)\n",
    "    plt.rc('xtick', labelsize=14) \n",
    "    plt.rc('ytick', labelsize=14) \n",
    "    plt.ioff()\n",
    "    plt.autoscale()\n",
    "    if not name==None:\n",
    "        plt.savefig(name,  bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c5a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, X=None, y=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def set_data(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.read_data_torch()\n",
    "    def read_data_torch(self):\n",
    "        self.X_train =  torch.FloatTensor(self.X)\n",
    "        self.y_train =  torch.FloatTensor(self.y)\n",
    "        self.X_test =  torch.FloatTensor(self.X)\n",
    "        self.y_test =  torch.FloatTensor(self.y)\n",
    "    def read_data(self, inp):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aed2b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full GP \n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ZeroMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ba7391",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactGPyTorchRegression:\n",
    "    def __init__(self, data):\n",
    "        # Change dataset to torch tensor\n",
    "        self.data = data\n",
    "        data.read_data(\"torch\")\n",
    "        self.likelihood = []\n",
    "        self.model = []\n",
    "    def fit(self):\n",
    "        for i in range(self.data.y.shape[1]):\n",
    "            likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "            model = ExactGPModel(self.data.X_train, self.data.y_train[:,i], likelihood)\n",
    "            # Use the adam optimizer\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "            # \"Loss\" for GPs - the marginal log likelihood\n",
    "            mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "            training_iter = 50\n",
    "            for j in range(training_iter):\n",
    "                # Zero gradients from previous iteration\n",
    "                optimizer.zero_grad()\n",
    "                # Output from model\n",
    "                output = likelihood(model(self.data.X_train))\n",
    "                # Calc loss and backprop gradients\n",
    "                loss = -mll(output, self.data.y_train[:,i])\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            self.likelihood.append(likelihood)\n",
    "            self.model.append(model)        \n",
    "    def get_kernel_params(self):\n",
    "        self.sigma_f = []\n",
    "        self.length_scale = []\n",
    "        self.variance = []\n",
    "        self.sigma_n = []\n",
    "        for i in range(self.data.y.shape[1]):\n",
    "            self.sigma_f.append(self.model[i].covar_module.outputscale.item())\n",
    "            self.length_scale.append([self.model[i].covar_module.base_kernel.kernels[0].lengthscale.detach().numpy().item(0),\n",
    "                                      self.model[i].covar_module.base_kernel.kernels[0].lengthscale.detach().numpy().item(1)])\n",
    "            self.variance.append(self.model[i].covar_module.base_kernel.kernels[1].variance.item())\n",
    "            self.sigma_n.append(self.likelihood[i].noise_covar.noise.item())\n",
    "    def save_kernel_params(self):\n",
    "        self.get_kernel_params()\n",
    "        for i in range(self.data.y.shape[1]):\n",
    "            name = \"gpytorch_y\" + str(i+1) + \"_\" + str(self.batch_size) + \"_\" + str(self.n_epochs)\n",
    "            self.data.save_kernel_params(name, self.length_scale[i], self.sigma_f[i], self.variance[i], self.sigma_n[i])\n",
    "    def predict(self, X_test=None):\n",
    "        if X_test == None:\n",
    "            X_test = self.X_test\n",
    "        self.mean = np.empty(X_test.shape)\n",
    "        self.upper = np.empty(X_test.shape)\n",
    "        self.lower = np.empty(X_test.shape)\n",
    "        for i in range(self.data.y.shape[1]):\n",
    "            self.model[i].eval()\n",
    "            self.likelihood[i].eval()\n",
    "            observed_pred = self.likelihood[i]((self.model[i](X_test)))\n",
    "            self.mean[:,i] = observed_pred.mean.detach().numpy()\n",
    "            lower, upper = observed_pred.confidence_region()\n",
    "            self.upper[:,i] = upper.detach().numpy()\n",
    "            self.lower[:,i] = lower.detach().numpy()\n",
    "        #name = \"gpytorch\" + \"_\" + str(self.batch_size) + \"_\" + str(self.n_epochs)\n",
    "        #self.data.save_prediction(name, self.mean, self.upper, self.lower)\n",
    "    def save_model(self):\n",
    "        for i in range(self.data.y.shape[1]):\n",
    "            print(self.model[i].state_dict())\n",
    "            name = \"gpytorch_y\" + str(i+1) + \"_model.pth\"\n",
    "            torch.save(self.model[i].state_dict(), name)\n",
    "            name = \"gpytorch_y\" + str(i+1) + \"_likelihood.pth\"\n",
    "            torch.save(self.likelihood[i].state_dict(), name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b867ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare ground thruth against results with surface plot\n",
    "def plot_surface(x, y, mean, true, upper, lower, bounds, name=None):\n",
    "    mean_grid = mean.reshape(x.shape)\n",
    "    true_grid = true.reshape(x.shape)\n",
    "    fig = plt.figure()\n",
    "    # scale to 0.995% confidence interval\n",
    "    #upper = 0.5 * 2.807 * upper\n",
    "    #lower = 0.5 * 2.807 * lower\n",
    "    var = (upper - mean)/2\n",
    "    var_chi = var * 2.807\n",
    "    upper = mean + var_chi\n",
    "    lower = mean - var_chi\n",
    "    if bounds:\n",
    "        upper_grid = upper.reshape(x.shape)\n",
    "        lower_grid = lower.reshape(x.shape)\n",
    "        ax = fig.gca(projection='3d')\n",
    "        #ax.plot_surface(x, y, mean_grid,  color='C0', alpha=0.8)\n",
    "        ax.plot_surface(x, y, true_grid,  color='C3', alpha=1)\n",
    "        ax.plot_surface(x, y, upper_grid, cmap=cm.coolwarm, alpha=0.5)\n",
    "        ax.plot_surface(x, y, lower_grid, cmap=cm.coolwarm, alpha=0.5)\n",
    "    else:\n",
    "        ax1 = fig.subplots(1, 1)\n",
    "        ax1 = plt.contourf(x, y, mean_grid-true_grid, cmap='coolwarm')\n",
    "        cbar = fig.colorbar(ax1)\n",
    "    plt.ioff()\n",
    "    if not name==None:\n",
    "        plt.savefig(name,  bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f68ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_input_data(X, y1, y2, title):\n",
    "    fig, axs = plt.subplots(2, 3)\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    axs[0, 0].remove()\n",
    "    ax1 = fig.add_subplot(2, 3, 1, projection='3d')\n",
    "    ax1.scatter(X[:, 0], X[:, 1], y1)\n",
    "    axs[0, 1].plot(X[:,0], y1, 'r*')\n",
    "    axs[0, 1].set_xlabel(\"x-direction[m]\")\n",
    "    axs[0, 1].set_ylabel(\"force in x-direction [m/s^2]\")\n",
    "    axs[0, 2].plot(X[:,1], y1, 'g*')\n",
    "    axs[0, 2].set_xlabel(\"y-direction[m]\")\n",
    "    axs[0, 2].set_ylabel(\"force in x-direction [m/s^2]\")\n",
    "    axs[1, 0].remove()\n",
    "    ax4 = fig.add_subplot(2, 3, 4, projection='3d')\n",
    "    ax4.scatter(X[:, 0], X[:, 1], y2)\n",
    "    axs[1, 1].plot(X[:, 0], y2, 'r*')\n",
    "    axs[1, 1].set_xlabel(\"x-direction[m]\")\n",
    "    axs[1, 1].set_ylabel(\"force in y-direction [m/s^2]\")\n",
    "    axs[1, 2].plot(X[:, 1], y2, 'g*')\n",
    "    axs[1, 2].set_xlabel(\"y-direction[m]\")\n",
    "    axs[1, 2].set_ylabel(\"force in y-direction [m/s^2]\")\n",
    "    fig.suptitle(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dde6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coordinate_distance(a, b):\n",
    "    return ((a[0]-b[0])**2+(a[1]-b[1])**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce4288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_distance_matrix(X_path):\n",
    "    distance_matrix = np.zeros((X_path.shape[0],X_path.shape[0]))\n",
    "    for i in range(X_path.shape[0]):\n",
    "        for j in range(X_path.shape[0]):\n",
    "            distance = compute_coordinate_distance(X_path[i], X_path[j])\n",
    "            distance_matrix[i,j] = distance\n",
    "    return distance_matrix\n",
    "\n",
    "def compute_permutation(X_path):\n",
    "    distance_matrix = create_distance_matrix(X_path)\n",
    "    permutation, distance = solve_tsp_dynamic_programming(distance_matrix)\n",
    "    return permutation\n",
    "\n",
    "def solve_tsp(X_path):\n",
    "    permutation = compute_permutation(X_path)\n",
    "    X_tsp = X_path[permutation,:]\n",
    "    return X_tsp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d88451",
   "metadata": {},
   "source": [
    "# Ground Truth Windfield"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb28dad",
   "metadata": {},
   "source": [
    "## Create Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9caae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_grid, x_grid, y_grid = create_grid(-9.9,9.9,51)\n",
    "X_grid_torch, x_grid_torch, y_grid_torch = create_grid(-9.9,9.9,51, \"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ec5f39",
   "metadata": {},
   "source": [
    "## Define wind field parameters and compute wind field "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7010e7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_field_parameters = {'use_custom_windfield': True, \\\n",
    "                         'wind_direction': np.array([1.0, 1.0, 0.0]), \\\n",
    "                         'wind_velocity': 1.0, \\\n",
    "                         'x':x_grid, 'y':y_grid, \\\n",
    "                         'windfield_path':'/home/johanna/uav_mpcc/src/model_sim/include/custom_wind_fields/fan_x_dir_strength_5.txt'}\n",
    "wind_calculator = WindCalculator(wind_field_parameters)\n",
    "wind_gt = wind_calculator.return_ground_truth()[:,0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a2711f",
   "metadata": {},
   "source": [
    "## Visualize the windfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1b9ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wind_field(X_grid, wind_gt, 4, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e647bed7",
   "metadata": {},
   "source": [
    "# Active learning example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8015ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = np.load('/home/johanna/MasterThesis/final_data/GP_training/matern_path_x_no_noise/wind_data_4.npz')\n",
    "X1 = data1['X'][:,:]\n",
    "y1 = data1['y'][:,:]\n",
    "data1 = Data()\n",
    "data1.set_data(X1,y1)\n",
    "plot_wind_field(X1, y1, 4, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097958f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = np.load('/home/johanna/MasterThesis/final_data/GP_training/SE_path_x_final_no_noise2/wind_data_4.npz')\n",
    "X2 = data2['X'][:,:]\n",
    "y2 = data2['y'][:,:]\n",
    "data2 = Data()\n",
    "data2.set_data(X2,y2)\n",
    "plot_wind_field(X2, y2, 4, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccffb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_gp_torch = SparseGPyTorchRegression(data2, 20, 20)\n",
    "train = False\n",
    "if train:\n",
    "    sparse_gp_torch.fit()\n",
    "    sparse_gp_torch.predict(X_grid_torch)\n",
    "    y_pred = sparse_gp_torch.mean\n",
    "    MSE = mean_squared_error(wind_gt, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9e93d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncertainty map\n",
    "if train:\n",
    "    unc_y0 = (sparse_gp_torch.upper[:,0] - sparse_gp_torch.mean[:,0])/2\n",
    "    unc_y1 = (sparse_gp_torch.upper[:,1] - sparse_gp_torch.mean[:,1])/2\n",
    "    name = '/home/johanna/thesis_plots/active_learning_1'\n",
    "    unc = (unc_y0 + unc_y1).reshape(51,51)\n",
    "    fig = plt.figure()\n",
    "    w = 5\n",
    "    h = 5\n",
    "    fig.set_size_inches(w,h)\n",
    "    contourf_ = plt.contourf(x_grid, y_grid, unc, cmap='coolwarm')\n",
    "    cbar = fig.colorbar(contourf_)\n",
    "    plt.xlabel('x [m]', fontsize=14)\n",
    "    plt.ylabel('y [m]', fontsize=14)\n",
    "    plt.rc('xtick', labelsize=14) \n",
    "    plt.rc('ytick', labelsize=14) \n",
    "    plt.xlim([-9.9,9.9])\n",
    "    plt.ylim([-9.9,9.9])\n",
    "    if not name==None:\n",
    "        plt.savefig(name,  bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce7c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Most uncertain point plus radius\n",
    "if train:\n",
    "    name = '/home/johanna/thesis_plots/active_learning_2'\n",
    "    n_points = 10\n",
    "    radius = 2\n",
    "    fig, ax = plt.subplots()\n",
    "    w = 5\n",
    "    h = 5\n",
    "    fig.set_size_inches(w,h)\n",
    "    idx_0 = np.argsort(unc_y0 + unc_y1)[-1]\n",
    "    X_path = []\n",
    "    X_path.append(X_grid[idx_0])\n",
    "    ax.plot(X_path[0][0],X_path[0][1], 'rX')\n",
    "    circle=plt.Circle((X_path[0]),radius,color='b', fill=False)\n",
    "    ax.add_patch(circle)\n",
    "\n",
    "    i = 2\n",
    "    k = 0\n",
    "    while (len(X_path) < n_points):\n",
    "        idx = np.argsort(unc_y0 + unc_y1)[-i]\n",
    "        X_samp = X_grid[idx]\n",
    "        dist_array = []\n",
    "        for j in range(len(X_path)):\n",
    "            dist = compute_coordinate_distance(X_samp, X_path[j])\n",
    "            dist_array.append(dist)\n",
    "            #ax.plot(X_samp[0],X_samp[1], color='0.8', marker='.')\n",
    "        if not any(k < radius for k in dist_array):\n",
    "            X_path.append(X_samp)\n",
    "            k = k+1\n",
    "            #ax.plot(X_path[k][0],X_path[k][1], 'rX')\n",
    "            #circle=plt.Circle((X_path[k]),radius,color='b', fill=False)\n",
    "            #ax.add_patch(circle)\n",
    "        i = i+1\n",
    "    plt.xlim([-10,10])\n",
    "    plt.ylim([-10,10])\n",
    "    ax.set_aspect('equal')\n",
    "    plt.xlabel('x [m]', fontsize=14)\n",
    "    plt.ylabel('y [m]', fontsize=14)\n",
    "    plt.rc('xtick', labelsize=14) \n",
    "    plt.rc('ytick', labelsize=14)\n",
    "    if not name==None:\n",
    "        plt.savefig(name,  bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de131dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train: \n",
    "    name = '/home/johanna/thesis_plots/active_learning_4'\n",
    "    X_path = np.reshape(X_path, (-1,2))\n",
    "    X_tsp = solve_tsp(X_path)\n",
    "    fig, ax = plt.subplots()\n",
    "    w = 5\n",
    "    h = 5\n",
    "    fig.set_size_inches(w,h)\n",
    "    plt.plot(X_tsp[:,0],X_tsp[:,1], '-rX')\n",
    "    plt.xlim([-10,10])\n",
    "    plt.ylim([-10,10])\n",
    "    ax.set_aspect('equal')\n",
    "    plt.xlabel('x [m]', fontsize=14)\n",
    "    plt.ylabel('y [m]', fontsize=14)\n",
    "    plt.rc('xtick', labelsize=14) \n",
    "    plt.rc('ytick', labelsize=14) \n",
    "    plt.axis('equal')\n",
    "    if not name==None:\n",
    "        plt.savefig(name,  bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc03d54",
   "metadata": {},
   "source": [
    "## Epochs and Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8875a3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_list = np.array([0])\n",
    "time_list = np.array([0])\n",
    "var_list = np.array([0])\n",
    "train = False #Set to true to do training\n",
    "if train: \n",
    "    batch_size_list = [10] #,20,30,40,50]\n",
    "    n_epochs_list = [10] #,20,30,40,50]\n",
    "    for i in range(len(n_epochs_list)):\n",
    "        for j in range(len(batch_size_list)):\n",
    "            tic = time.time()\n",
    "            sparse_gp_torch = SparseGPyTorchRegression(data2, batch_size_list[j], n_epochs_list[i])\n",
    "            sparse_gp_torch.fit()\n",
    "            sparse_gp_torch.predict(X_grid_torch)\n",
    "            y_pred = sparse_gp_torch.mean\n",
    "            var = np.mean((sparse_gp_torch.upper - sparse_gp_torch.mean)/2)\n",
    "            MSE = mean_squared_error(wind_gt, y_pred)\n",
    "            toc = time.time() - tic\n",
    "            MSE_list = np.append(MSE_list, MSE)\n",
    "            time_list = np.append(time_list, toc)\n",
    "            var_list = np.append(var_list, var)\n",
    "    #np.savez('/home/johanna/MasterThesis/data/SE_path_x_final_no_noise2/results_final.npz', time = time_list, MSE = MSE_list, var = var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a97bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SE_data = np.load('/home/johanna/MasterThesis/final_data/GP_training/SE_path_x_final_no_noise2/results_final.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8824f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a figure to compare the MSE data \n",
    "#MSE_matern = matern_data[\"MSE\"][1:].reshape((5,5))\n",
    "#time_matern = matern_data[\"time\"][1:].reshape((5,5))\n",
    "MSE_SE = SE_data[\"MSE\"][1:].reshape((5,5))\n",
    "time_SE = SE_data[\"time\"][1:].reshape((5,5))\n",
    "unc_SE = SE_data[\"var\"][1:].reshape((5,5))\n",
    "#df_MSE_matern = pd.DataFrame(MSE_matern, columns = ['b10','b20','b30','b40','b50'])\n",
    "#df_time_matern = pd.DataFrame(time_matern, columns = ['b10','b20','b30','b40','b50'])\n",
    "df_MSE_SE = pd.DataFrame(MSE_SE, columns = ['b10','b20','b30','b40','b50'])\n",
    "df_time_SE = pd.DataFrame(time_SE, columns = ['b10','b20','b30','b40','b50'])\n",
    "df_unc_SE = pd.DataFrame(unc_SE, columns = ['b10','b20','b30','b40','b50'])\n",
    "# Save to .csv file for plotting in latex\n",
    "save = False \n",
    "if save: \n",
    "    df_MSE_SE.to_csv('/home/johanna/thesis_plots/MSE.csv')\n",
    "    df_time_SE.to_csv('/home/johanna/thesis_plots/time.csv')\n",
    "    df_unc_SE.to_csv('/home/johanna/thesis_plots/unc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68be4edf",
   "metadata": {},
   "source": [
    "## Matern versus SE kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda1ccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matern Kernel 2\n",
    "data1 = np.load('/home/johanna/MasterThesis/final_data/GP_training/matern_path_field2/wind_data_1.npz')\n",
    "data2 = np.load('/home/johanna/MasterThesis/final_data/GP_training/matern_path_field2/wind_data_2.npz')\n",
    "data3 = np.load('/home/johanna/MasterThesis/final_data/GP_training/matern_path_field2/wind_data_3.npz')\n",
    "data4 = np.load('/home/johanna/MasterThesis/final_data/GP_training/matern_path_field2/wind_data_4.npz')\n",
    "data5 = np.load('/home/johanna/MasterThesis/final_data/GP_training/matern_path_field2/wind_data_5.npz')\n",
    "data_list_matern_raw = [data1, data2, data3, data4, data5]\n",
    "data_list_matern_ = [data1, data2, data3, data4, data5]\n",
    "j = 0\n",
    "for i in data_list_matern_raw:\n",
    "    X1 = i['X'][:,:]\n",
    "    y1 = i['y'][:,:]\n",
    "    i = Data()\n",
    "    i.set_data(X1,y1)\n",
    "    data_list_matern_[j] = i\n",
    "    j = j+1\n",
    "    name = \"/home/johanna/thesis_plots/matern_path\" + str(j) + \".png\"\n",
    "    plot_path(X1, 1, None, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c420f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SE Kernel 2\n",
    "data1 = np.load('/home/johanna/MasterThesis/final_data/GP_training/gauss_path_field2/wind_data_1.npz')\n",
    "data2 = np.load('/home/johanna/MasterThesis/final_data/GP_training/gauss_path_field2/wind_data_2.npz')\n",
    "data3 = np.load('/home/johanna/MasterThesis/final_data/GP_training/gauss_path_field2/wind_data_3.npz')\n",
    "data4 = np.load('/home/johanna/MasterThesis/final_data/GP_training/gauss_path_field2/wind_data_4.npz')\n",
    "data5 = np.load('/home/johanna/MasterThesis/final_data/GP_training/gauss_path_field2/wind_data_5.npz')\n",
    "data_list_SE_raw = [data1, data2, data3, data4, data5]\n",
    "data_list_SE_ = [data1, data2, data3, data4, data5]\n",
    "j = 0\n",
    "for i in data_list_SE_raw:\n",
    "    X1 = i['X'][:,:]\n",
    "    y1 = i['y'][:,:]\n",
    "    i = Data()\n",
    "    i.set_data(X1,y1)\n",
    "    data_list_SE_[j] = i\n",
    "    j = j+1\n",
    "    name = \"/home/johanna/thesis_plots/SE_path\" + str(j) + \".png\"\n",
    "    plot_path(X1, 1, None, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07031863",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_list_SE = np.array([0])\n",
    "mean_unc_list_SE = np.array([0])\n",
    "max_unc_list_SE = np.array([0])\n",
    "train = False #Set to true to do training\n",
    "if train: \n",
    "    batch_size_list = [10,20,30,40,50]\n",
    "    n_epochs = 20\n",
    "    for j in range(len(data_list_SE_)):\n",
    "        sparse_gp_torch = SparseGPyTorchRegression(data_list_SE_[j], batch_size_list[j], n_epochs)\n",
    "        sparse_gp_torch.fit()\n",
    "        sparse_gp_torch.predict(X_grid_torch)\n",
    "        y_pred = sparse_gp_torch.mean\n",
    "        MSE = mean_squared_error(wind_gt, y_pred)\n",
    "        mean_unc = np.mean((sparse_gp_torch.upper - sparse_gp_torch.mean)/2)\n",
    "        max_unc = np.max((sparse_gp_torch.upper - sparse_gp_torch.mean)/2)\n",
    "        MSE_list_SE = np.append(MSE_list_SE, MSE)\n",
    "        mean_unc_list_SE = np.append(mean_unc_list_SE, mean_unc)\n",
    "        max_unc_list_SE = np.append(max_unc_list_SE, max_unc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4631e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_list_matern = np.array([0])\n",
    "mean_unc_list_matern = np.array([0])\n",
    "max_unc_list_matern = np.array([0])\n",
    "train = False #Set to true to do training\n",
    "if train: \n",
    "    batch_size_list = [10,20,30,40,50]\n",
    "    n_epochs = 20\n",
    "    for j in range(len(data_list_matern_)):\n",
    "        sparse_gp_torch = SparseGPyTorchRegression(data_list_matern_[j], batch_size_list[j], n_epochs)\n",
    "        sparse_gp_torch.fit()\n",
    "        sparse_gp_torch.predict(X_grid_torch)\n",
    "        y_pred = sparse_gp_torch.mean\n",
    "        MSE = mean_squared_error(wind_gt, y_pred)\n",
    "        mean_unc = np.mean((sparse_gp_torch.upper - sparse_gp_torch.mean)/2)\n",
    "        max_unc = np.max((sparse_gp_torch.upper - sparse_gp_torch.mean)/2)\n",
    "        MSE_list_matern = np.append(MSE_list_matern, MSE)\n",
    "        mean_unc_list_matern = np.append(mean_unc_list_matern, mean_unc)\n",
    "        max_unc_list_matern = np.append(max_unc_list_matern, max_unc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bfd640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data for plotting in in latex\n",
    "if train:\n",
    "    MSE_compare = pd.DataFrame(np.vstack((MSE_list_matern, MSE_list_SE)).transpose(), columns = ['matern','SE'])\n",
    "    unc_compare = pd.DataFrame(np.vstack((mean_unc_list_matern, mean_unc_list_SE, max_unc_list_matern, max_unc_list_SE)).transpose(), columns = ['matern_mean','SE_mean','matern_max','SE_max'])\n",
    "    MSE_compare.to_csv('/home/johanna/thesis_plots/MSE_compare.csv')\n",
    "    unc_compare.to_csv('/home/johanna/thesis_plots/unc_compare.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1c25bc",
   "metadata": {},
   "source": [
    "## Different path comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629d3b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structured path \n",
    "data1 = np.load('/home/johanna/MasterThesis/final_data/GP_training/structured_path/wind_data_1.npz')\n",
    "X1 = data1['X'][:,:]\n",
    "y1 = data1['y'][:,:]\n",
    "data1 = Data()\n",
    "data1.set_data(X1,y1)\n",
    "plot_wind_field(X1, y1, 4, None, \"/home/johanna/thesis_plots/structured_data\")\n",
    "tic = time.time()\n",
    "sparse_gp_torch = SparseGPyTorchRegression(data1, 80, 20)\n",
    "sparse_gp_torch.fit()\n",
    "toc = time.time() -tic\n",
    "sparse_gp_torch.predict(X_grid_torch)\n",
    "y_pred = sparse_gp_torch.mean\n",
    "MSE = mean_squared_error(wind_gt, y_pred)\n",
    "unc_y0 = (sparse_gp_torch.upper[:,0] - sparse_gp_torch.mean[:,0])/2\n",
    "unc_y1 = (sparse_gp_torch.upper[:,1] - sparse_gp_torch.mean[:,1])/2\n",
    "unc = (unc_y0 + unc_y1)\n",
    "mean_unc = np.mean(unc)\n",
    "max_unc = np.max(unc)\n",
    "print(MSE, mean_unc, max_unc, toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434ce376",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wind_field(X_grid_torch, y_pred, 4, None, \"/home/johanna/thesis_plots/structured_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4591d8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncertainty map\n",
    "unc_y0 = (sparse_gp_torch.upper[:,0] - sparse_gp_torch.mean[:,0])/2\n",
    "unc_y1 = (sparse_gp_torch.upper[:,1] - sparse_gp_torch.mean[:,1])/2\n",
    "name = '/home/johanna/thesis_plots/unc_structured_path'\n",
    "unc = (unc_y0 + unc_y1).reshape(51,51)\n",
    "fig = plt.figure()\n",
    "w = 5\n",
    "h = 5\n",
    "fig.set_size_inches(w,h)\n",
    "contourf_ = plt.contourf(x_grid, y_grid, unc, cmap='coolwarm')\n",
    "cbar = fig.colorbar(contourf_)\n",
    "plt.xlabel('x [m]', fontsize=14)\n",
    "plt.ylabel('y [m]', fontsize=14)\n",
    "plt.rc('xtick', labelsize=14) \n",
    "plt.rc('ytick', labelsize=14) \n",
    "plt.xlim([-9.9,9.9])\n",
    "plt.ylim([-9.9,9.9])\n",
    "if not name==None:\n",
    "    plt.savefig(name,  bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bdacad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemniscate trajectory \n",
    "def read_data(filepath):\n",
    "    training_data = pd.read_csv(filepath)\n",
    "    training_data_array = training_data.to_numpy()\n",
    "    X = np.stack((training_data_array[:, 0], training_data_array[:, 1]), axis=-1)\n",
    "    y1 = training_data_array[:, 2]\n",
    "    y2 = training_data_array[:, 3]\n",
    "    y = np.vstack((y1,y2)).transpose()\n",
    "    return X, y\n",
    "X, y = read_data('/home/johanna/MasterThesis/final_data/GP_training/lemniscate_path/lmpcc_windsimplesim_fan_xy_dir_2022-09-07-10-48-53.csv')\n",
    "data1 = Data()\n",
    "data1.set_data(X,y)\n",
    "plot_wind_field(X, y, 4, None, \"/home/johanna/thesis_plots/lemniscate_data\")\n",
    "tic = time.time()\n",
    "sparse_gp_torch = SparseGPyTorchRegression(data1, 20, 20)\n",
    "sparse_gp_torch.fit()\n",
    "toc = time.time() -tic\n",
    "sparse_gp_torch.predict(X_grid_torch)\n",
    "y_pred = sparse_gp_torch.mean\n",
    "MSE = mean_squared_error(wind_gt, y_pred)\n",
    "unc_y0 = (sparse_gp_torch.upper[:,0] - sparse_gp_torch.mean[:,0])/2\n",
    "unc_y1 = (sparse_gp_torch.upper[:,1] - sparse_gp_torch.mean[:,1])/2\n",
    "unc = (unc_y0 + unc_y1)\n",
    "mean_unc = np.mean(unc)\n",
    "max_unc = np.max(unc)\n",
    "print(MSE, mean_unc, max_unc,toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fbcc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wind_field(X_grid_torch, y_pred, 4, None, \"/home/johanna/thesis_plots/lemniscate_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a635b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncertainty map\n",
    "unc_y0 = (sparse_gp_torch.upper[:,0] - sparse_gp_torch.mean[:,0])/2\n",
    "unc_y1 = (sparse_gp_torch.upper[:,1] - sparse_gp_torch.mean[:,1])/2\n",
    "name = '/home/johanna/thesis_plots/unc_lemniscate'\n",
    "unc = (unc_y0 + unc_y1).reshape(51,51)\n",
    "fig = plt.figure()\n",
    "w = 5\n",
    "h = 5\n",
    "fig.set_size_inches(w,h)\n",
    "contourf_ = plt.contourf(x_grid, y_grid, unc, cmap='coolwarm')\n",
    "cbar = fig.colorbar(contourf_)\n",
    "plt.xlabel('x [m]', fontsize=14)\n",
    "plt.ylabel('y [m]', fontsize=14)\n",
    "plt.rc('xtick', labelsize=14) \n",
    "plt.rc('ytick', labelsize=14) \n",
    "plt.xlim([-9.9,9.9])\n",
    "plt.ylim([-9.9,9.9])\n",
    "if not name==None:\n",
    "    plt.savefig(name,  bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5afe4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Active learning trajectory\n",
    "data1 = np.load('/home/johanna/MasterThesis/final_data/GP_training/SE_path_field_xy/wind_data_5.npz')\n",
    "X1 = data1['X'][:,:]\n",
    "y1 = data1['y'][:,:]\n",
    "data1 = Data()\n",
    "data1.set_data(X1,y1)\n",
    "plot_wind_field(X1, y1, 4, None, \"/home/johanna/thesis_plots/AL_data\")\n",
    "tic = time.time()\n",
    "sparse_gp_torch = SparseGPyTorchRegression(data1, 30, 20)\n",
    "sparse_gp_torch.fit()\n",
    "toc = time.time() -tic\n",
    "sparse_gp_torch.predict(X_grid_torch)\n",
    "y_pred = sparse_gp_torch.mean_\n",
    "MSE = mean_squared_error(wind_gt, y_pred)\n",
    "unc_y0 = (sparse_gp_torch.upper[:,0] - sparse_gp_torch.mean[:,0])/2\n",
    "unc_y1 = (sparse_gp_torch.upper[:,1] - sparse_gp_torch.mean[:,1])/2\n",
    "unc = (unc_y0 + unc_y1)\n",
    "mean_unc = np.mean(unc)\n",
    "max_unc = np.max(unc)\n",
    "print(MSE, mean_unc, max_unc, toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7537fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wind_field(X_grid_torch, y_pred, 4, None, \"/home/johanna/thesis_plots/AL_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6178f959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncertainty map\n",
    "unc_y0 = (sparse_gp_torch.upper[:,0] - sparse_gp_torch.mean[:,0])/2\n",
    "unc_y1 = (sparse_gp_torch.upper[:,1] - sparse_gp_torch.mean[:,1])/2\n",
    "name = '/home/johanna/thesis_plots/unc_active_learning'\n",
    "unc = (unc_y0 + unc_y1).reshape(51,51)\n",
    "fig = plt.figure()\n",
    "w = 5\n",
    "h = 5\n",
    "fig.set_size_inches(w,h)\n",
    "contourf_ = plt.contourf(x_grid, y_grid, unc, cmap='coolwarm')\n",
    "cbar = fig.colorbar(contourf_)\n",
    "plt.xlabel('x [m]', fontsize=14)\n",
    "plt.ylabel('y [m]', fontsize=14)\n",
    "plt.rc('xtick', labelsize=14) \n",
    "plt.rc('ytick', labelsize=14) \n",
    "plt.xlim([-9.9,9.9])\n",
    "plt.ylim([-9.9,9.9])\n",
    "if not name==None:\n",
    "    plt.savefig(name,  bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25bbb6e",
   "metadata": {},
   "source": [
    "## Full versus sparse GP comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd827619",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('/home/johanna/MasterThesis/final_data/GP_training/SE_path_x_final_no_noise2/wind_data_4.npz')\n",
    "X = data['X'][:,:]\n",
    "y = data['y'][:,:]\n",
    "data = Data()\n",
    "data.set_data(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd225348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full GP model \n",
    "tic = time.time()\n",
    "exact_gp_torch = ExactGPyTorchRegression(data)\n",
    "exact_gp_torch.fit()\n",
    "toc = time.time() -tic\n",
    "tic = time.time()\n",
    "exact_gp_torch.predict(X_grid_torch)\n",
    "y_pred = exact_gp_torch.mean\n",
    "toc2 = time.time() -tic\n",
    "MSE = mean_squared_error(wind_gt, y_pred)\n",
    "unc_y0 = (exact_gp_torch.upper[:,0] - exact_gp_torch.mean[:,0])/2\n",
    "unc_y1 = (exact_gp_torch.upper[:,1] - exact_gp_torch.mean[:,1])/2\n",
    "unc = (unc_y0 + unc_y1)\n",
    "mean_unc = np.mean(unc)\n",
    "max_unc = np.max(unc)\n",
    "print(MSE, mean_unc, max_unc, toc, toc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff634988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse GP model \n",
    "tic = time.time()\n",
    "sparse_gp_torch = SparseGPyTorchRegression(data, 40, 20)\n",
    "sparse_gp_torch.fit()\n",
    "toc = time.time() -tic\n",
    "tic = time.time()\n",
    "sparse_gp_torch.predict(X_grid_torch)\n",
    "y_pred = sparse_gp_torch.mean\n",
    "toc2 = time.time() -tic\n",
    "MSE = mean_squared_error(wind_gt, y_pred)\n",
    "unc_y0 = sparse_gp_torch.upper[:,0] - sparse_gp_torch.mean[:,0]\n",
    "unc_y1 = sparse_gp_torch.upper[:,1] - sparse_gp_torch.mean[:,1]\n",
    "unc = (unc_y0 + unc_y1)\n",
    "mean_unc = np.mean(unc)\n",
    "max_unc = np.max(unc)\n",
    "print(MSE, mean_unc, max_unc, toc, toc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32ab872",
   "metadata": {},
   "source": [
    "## Follow up windfields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be64a01",
   "metadata": {},
   "source": [
    "### 1.1) X field - no noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1e1468",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = np.load('/home/johanna/MasterThesis/final_data/GP_training/SE_path_x_final_no_noise2/wind_data_4.npz')\n",
    "X = data_x['X'][:,:]\n",
    "y = data_x['y'][:,:]\n",
    "data_x = Data()\n",
    "data_x.set_data(X,y)\n",
    "plot_wind_field(X, y, 1, None, \"/home/johanna/thesis_plots/final_x_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7476ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "sparse_gp_torch = SparseGPyTorchRegression(data_x, 40, 20)\n",
    "sparse_gp_torch.fit()\n",
    "#sparse_gp_torch.save_model(\"_wind_x_final\")\n",
    "toc = time.time() -tic\n",
    "tic = time.time()\n",
    "sparse_gp_torch.predict(X_grid_torch)\n",
    "y_pred = sparse_gp_torch.mean\n",
    "toc2 = time.time() -tic\n",
    "MSE = mean_squared_error(wind_gt, y_pred)\n",
    "unc_y0 = (sparse_gp_torch.upper[:,0] - sparse_gp_torch.mean[:,0])/2\n",
    "unc_y1 = (sparse_gp_torch.upper[:,1] - sparse_gp_torch.mean[:,1])/2\n",
    "unc = (unc_y0 + unc_y1)\n",
    "mean_unc = np.mean(unc)\n",
    "max_unc = np.max(unc)\n",
    "print(MSE, mean_unc, max_unc, toc, toc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb5f038",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_gp_torch.get_kernel_params()\n",
    "len_scale = sparse_gp_torch.length_scale\n",
    "sigma_f  = sparse_gp_torch.sigma_f\n",
    "sigma_n = sparse_gp_torch.sigma_n\n",
    "print(len_scale, sigma_f, sigma_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a097a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wind_field(X_grid_torch, y_pred, 4, None, \"/home/johanna/thesis_plots/final_x_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d95f611",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plot_surface(x_grid, y_grid, sparse_gp_torch.mean[:,1], wind_gt[:,1], sparse_gp_torch.upper[:,1], sparse_gp_torch.lower[:,1], True)\n",
    "plot_surface(x_grid, y_grid, sparse_gp_torch.mean[:,0], wind_gt[:,0], sparse_gp_torch.upper[:,0], sparse_gp_torch.lower[:,0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb25fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plot_surface(x_grid, y_grid, sparse_gp_torch.mean[:,1], wind_gt[:,1], sparse_gp_torch.upper[:,1], sparse_gp_torch.lower[:,1], False, name = \"/home/johanna/thesis_plots/mean_surface_wind_x_y\")\n",
    "plot_surface(x_grid, y_grid, sparse_gp_torch.mean[:,0], wind_gt[:,0], sparse_gp_torch.upper[:,0], sparse_gp_torch.lower[:,0], False, name = \"/home/johanna/thesis_plots/mean_surface_wind_x_x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc271de5",
   "metadata": {},
   "source": [
    "### 1.2) X-field noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e73149",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x_noise = np.load('/home/johanna/MasterThesis/final_data/GP_training/SE_path_x_final_noise/wind_data_4.npz')\n",
    "X = data_x_noise['X'][:,:]\n",
    "y = data_x_noise['y'][:,:]\n",
    "data_x_noise = Data()\n",
    "data_x_noise.set_data(X,y)\n",
    "plot_wind_field(X, y, 1, None, \"/home/johanna/thesis_plots/final_x_data_noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b045c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "sparse_gp_torch = SparseGPyTorchRegression(data_x_noise, 40, 20)\n",
    "sparse_gp_torch.fit()\n",
    "sparse_gp_torch.save_model(\"_wind_x_final_noise\")\n",
    "toc = time.time() -tic\n",
    "tic = time.time()\n",
    "sparse_gp_torch.predict(X_grid_torch)\n",
    "y_pred = sparse_gp_torch.mean\n",
    "toc2 = time.time() -tic\n",
    "MSE = mean_squared_error(wind_gt, y_pred)\n",
    "unc_y0 = sparse_gp_torch.upper[:,0] - sparse_gp_torch.mean[:,0]\n",
    "unc_y1 = sparse_gp_torch.upper[:,1] - sparse_gp_torch.mean[:,1]\n",
    "unc = (unc_y0 + unc_y1)\n",
    "mean_unc = np.mean(unc)\n",
    "max_unc = np.max(unc)\n",
    "print(MSE, mean_unc, max_unc, toc, toc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03edb47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wind_field(X_grid_torch, y_pred, 4, None, \"/home/johanna/thesis_plots/final_x_results_noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f7a1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plot_surface(x_grid, y_grid, sparse_gp_torch.mean[:,1], wind_gt[:,1], sparse_gp_torch.upper[:,1], sparse_gp_torch.lower[:,1], True)\n",
    "plot_surface(x_grid, y_grid, sparse_gp_torch.mean[:,0], wind_gt[:,0], sparse_gp_torch.upper[:,0], sparse_gp_torch.lower[:,0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84e1cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plot_surface(x_grid, y_grid, sparse_gp_torch.mean[:,1], wind_gt[:,1], sparse_gp_torch.upper[:,1], sparse_gp_torch.lower[:,1], False, name = \"/home/johanna/thesis_plots/mean_surface_wind_x_y_noise\")\n",
    "plot_surface(x_grid, y_grid, sparse_gp_torch.mean[:,0], wind_gt[:,0], sparse_gp_torch.upper[:,0], sparse_gp_torch.lower[:,0], False, name = \"/home/johanna/thesis_plots/mean_surface_wind_x_x_noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee104cd2",
   "metadata": {},
   "source": [
    "### 2.1) x-y-field - no noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84a5637",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_field_parameters = {'use_custom_windfield': True, \\\n",
    "                         'wind_direction': np.array([1.0, 1.0, 0.0]), \\\n",
    "                         'wind_velocity': 1.0, \\\n",
    "                         'x':x_grid, 'y':y_grid, \\\n",
    "                         'windfield_path':'/home/johanna/uav_mpcc/src/model_sim/include/custom_wind_fields/fan_2_fans_random.txt'}\n",
    "wind_calculator = WindCalculator(wind_field_parameters)\n",
    "wind_gt = wind_calculator.return_ground_truth()[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf91fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xy_noise = np.load('/home/johanna/MasterThesis/final_data/GP_training/gauss_path_field2/wind_data_4.npz')\n",
    "X = data_xy_noise['X'][:,:]\n",
    "y = data_xy_noise['y'][:,:]\n",
    "data_xy_noise = Data()\n",
    "data_xy_noise.set_data(X,y)\n",
    "plot_wind_field(X, y, 1, None, \"/home/johanna/thesis_plots/final_xy_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e8c8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "sparse_gp_torch = SparseGPyTorchRegression(data_xy_noise, 40, 20)\n",
    "sparse_gp_torch.fit()\n",
    "#sparse_gp_torch.save_model(\"_wind_xy_final\")\n",
    "toc = time.time() -tic\n",
    "tic = time.time()\n",
    "sparse_gp_torch.predict(X_grid_torch)\n",
    "y_pred = sparse_gp_torch.mean\n",
    "toc2 = time.time() -tic\n",
    "MSE = mean_squared_error(wind_gt, y_pred)\n",
    "unc_y0 = sparse_gp_torch.upper[:,0] - sparse_gp_torch.mean[:,0]\n",
    "unc_y1 = sparse_gp_torch.upper[:,1] - sparse_gp_torch.mean[:,1]\n",
    "unc = (unc_y0 + unc_y1)\n",
    "mean_unc = np.mean(unc)\n",
    "max_unc = np.max(unc)\n",
    "print(MSE, mean_unc, max_unc, toc, toc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e04c5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wind_field(X_grid_torch, y_pred, 4, None, \"/home/johanna/thesis_plots/final_xy_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ea9286",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_gp_torch.get_kernel_params()\n",
    "len_scale = sparse_gp_torch.length_scale\n",
    "sigma_f  = sparse_gp_torch.sigma_f\n",
    "sigma_n = sparse_gp_torch.sigma_n\n",
    "print(len_scale, sigma_f, sigma_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a04a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plot_surface(x_grid, y_grid, sparse_gp_torch.mean[:,1], wind_gt[:,1], sparse_gp_torch.upper[:,1], sparse_gp_torch.lower[:,1], True)\n",
    "plot_surface(x_grid, y_grid, sparse_gp_torch.mean[:,0], wind_gt[:,0], sparse_gp_torch.upper[:,0], sparse_gp_torch.lower[:,0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa21f461",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_surface(x_grid, y_grid, sparse_gp_torch.mean[:,1], wind_gt[:,1], sparse_gp_torch.upper[:,1], sparse_gp_torch.lower[:,1], False, name = \"/home/johanna/thesis_plots/mean_surface_wind_xy_y\")\n",
    "plot_surface(x_grid, y_grid, sparse_gp_torch.mean[:,0], wind_gt[:,0], sparse_gp_torch.upper[:,0], sparse_gp_torch.lower[:,0], False, name = \"/home/johanna/thesis_plots/mean_surface_wind_xy_x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddee0fc6",
   "metadata": {},
   "source": [
    "### 2.2) x-y-field noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f2eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xy_noise = np.load('/home/johanna/MasterThesis/final_data/GP_training/SE_path_final_xy_noise/wind_data_4.npz')\n",
    "X = data_xy_noise['X'][:,:]\n",
    "y = data_xy_noise['y'][:,:]\n",
    "data_xy_noise = Data()\n",
    "data_xy_noise.set_data(X,y)\n",
    "plot_wind_field(X, y, 1, None, \"/home/johanna/thesis_plots/final_xy_data_noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3661bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "sparse_gp_torch = SparseGPyTorchRegression(data_xy_noise, 40, 20)\n",
    "sparse_gp_torch.fit()\n",
    "sparse_gp_torch.save_model(\"_wind_xy_final_noise\")\n",
    "toc = time.time() -tic\n",
    "tic = time.time()\n",
    "sparse_gp_torch.predict(X_grid_torch)\n",
    "y_pred = sparse_gp_torch.mean\n",
    "toc2 = time.time() -tic\n",
    "MSE = mean_squared_error(wind_gt, y_pred)\n",
    "unc_y0 = sparse_gp_torch.upper[:,0] - sparse_gp_torch.mean[:,0]\n",
    "unc_y1 = sparse_gp_torch.upper[:,1] - sparse_gp_torch.mean[:,1]\n",
    "unc = (unc_y0 + unc_y1)\n",
    "mean_unc = np.mean(unc)\n",
    "max_unc = np.max(unc)\n",
    "print(MSE, mean_unc, max_unc, toc, toc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c377653",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_gp_torch.get_kernel_params()\n",
    "len_scale = sparse_gp_torch.length_scale\n",
    "sigma_f  = sparse_gp_torch.sigma_f\n",
    "sigma_n = sparse_gp_torch.sigma_n\n",
    "print(len_scale, sigma_f, sigma_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35e32c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wind_field(X_grid_torch, y_pred/0.05, 4, None, \"/home/johanna/thesis_plots/final_xy_results_noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32bb499",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plot_surface(x_grid, y_grid, sparse_gp_torch.mean[:,1], wind_gt[:,1]*0.05, sparse_gp_torch.upper[:,1], sparse_gp_torch.lower[:,1], True)\n",
    "plot_surface(x_grid, y_grid, sparse_gp_torch.mean[:,0], wind_gt[:,0]*0.05, sparse_gp_torch.upper[:,0], sparse_gp_torch.lower[:,0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d64b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_surface(x_grid, y_grid, sparse_gp_torch.mean[:,1], wind_gt[:,1], sparse_gp_torch.upper[:,1], sparse_gp_torch.lower[:,1], False, name = \"/home/johanna/thesis_plots/mean_surface_wind_xy_x\")\n",
    "plot_surface(x_grid, y_grid, sparse_gp_torch.mean[:,0], wind_gt[:,0], sparse_gp_torch.upper[:,0], sparse_gp_torch.lower[:,0], False, name = \"/home/johanna/thesis_plots/mean_surface_wind_xy_y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75bd20f",
   "metadata": {},
   "source": [
    "# Discrete model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402b5c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xy_noise = np.load('/home/johanna/MasterThesis/final_data/GP_training/SE_path_xy_noise/wind_data_4.npz')\n",
    "X = data_xy_noise['X'][:,:]\n",
    "y = data_xy_noise['y'][:,:]*0.05\n",
    "data_xy_noise = Data()\n",
    "data_xy_noise.set_data(X,y)\n",
    "sparse_gp_torch_disc = SparseGPyTorchRegression(data_xy_noise, 40, 20)\n",
    "sparse_gp_torch_disc.fit()\n",
    "sparse_gp_torch_disc.save_model(\"_wind_xy_disc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84f3e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Winfield in x\n",
    "data_x_noise = np.load('/home/johanna/MasterThesis/final_data/GP_training/SE_path_x_noise/wind_data_3.npz')\n",
    "X = data_x_noise['X'][:,:]\n",
    "y = data_x_noise['y'][:,:]*0.05\n",
    "data_x_noise = Data()\n",
    "data_x_noise.set_data(X,y)\n",
    "sparse_gp_torch = SparseGPyTorchRegression(data_x_noise, 30, 20)\n",
    "sparse_gp_torch.fit()\n",
    "sparse_gp_torch.save_model(\"_wind_x_disc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fb2f5d",
   "metadata": {},
   "source": [
    "## Test the uncertain prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0862430",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.FloatTensor([[0,0]])\n",
    "sparse_gp_torch.predict(X_test)\n",
    "print(sparse_gp_torch.mean)\n",
    "print(((sparse_gp_torch.upper-sparse_gp_torch.mean)/2)**2)\n",
    "sparse_gp_torch.get_covar(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a73ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('/home/johanna/MasterThesis/final_data/GP_training/SE_path_xy_noise/wind_data_4.npz')\n",
    "data_X = data['X']\n",
    "data_y = data['y']\n",
    "inducing_points = torch.FloatTensor(data_X[::int(data_y.shape[0] / 30), :])\n",
    "\n",
    "# Load model in first direction\n",
    "model_vx = GPModel(inducing_points=inducing_points)\n",
    "state_dict = torch.load('/home/johanna/MasterThesis/Pyhton/gpytorch_y1_wind_x_final_model.pth')\n",
    "model_vx.load_state_dict(state_dict)\n",
    "state_dict = torch.load('/home/johanna/MasterThesis/Pyhton/gpytorch_y1_wind_x_final_likelihood.pth')\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "likelihood.load_state_dict(state_dict)\n",
    "likelihood_constraint = likelihood.noise_covar.raw_noise_constraint\n",
    "noise = likelihood_constraint.transform(state_dict['noise_covar.raw_noise'])\n",
    "observed_pred = likelihood((model_vx(X_test)))\n",
    "print(observed_pred.mean)\n",
    "print(observed_pred.covariance_matrix.detach().numpy())\n",
    "print(noise)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
